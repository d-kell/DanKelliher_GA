{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Prework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Tips\n",
    "1. Coding: Patsy, Train-Test-Split, GridSearchCV, GradientDescent, Cross Validation, Feature Selection, cPickle, Pipeline\n",
    "2. Machine Learning: Fix the Code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prework Tuesday\n",
    "1. Classification Models\n",
    "2. kNN (K-Nearest Neighbors) with sklearn\n",
    "3. Confusion Matrix\n",
    "\n",
    "## Prework Thursday\n",
    "1. Logistic Regression with sklearn\n",
    "2. Sigmoid Function, odds and odds ratio\n",
    "3. ROC/AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:2.5em;color:blue'>Coding Tips</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patsy\n",
    "\n",
    "Patsy is a simple way to split your data up into target and predictor values. It is very similar to statsmodel's OLS parameter formula. It is a handy way to add/remove features with ease. The generic formula of how to use patsy is below:\n",
    "\n",
    "```\n",
    "formula = 'target ~ predictor1 + predictor2 + predictor3 + predictor4 ... + predictor100 - 1'\n",
    "y, X    = patsy.dmatrices(formula, df=df, return_type='dataframe')\n",
    "```\n",
    "\n",
    "Since patsy changes y into a 2D array/dataframe, you have to change y into a 1D array/list. There are several ways to do it shown below.\n",
    "\n",
    "```\n",
    "y = y.values.ravel()\n",
    "y = df['target']\n",
    "```\n",
    "\n",
    "Next, I'll show you an example below on how to use patsy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('review_datasets/bikeshare.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = 'registered ~ temp + hum'\n",
    "y, X = patsy.dmatrices(formula, df, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   registered\n",
       "0        13.0\n",
       "1        32.0\n",
       "2        27.0\n",
       "3        10.0\n",
       "4         1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is now a 2D dataframe, we need to squish it back into a 1D array/list\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.,  32.,  27., ...,  83.,  48.,  37.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.ravel()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  temp   hum\n",
       "0        1.0  0.24  0.81\n",
       "1        1.0  0.22  0.80\n",
       "2        1.0  0.22  0.80\n",
       "3        1.0  0.24  0.75\n",
       "4        1.0  0.24  0.75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test_Split\n",
    "Train-Test split is one of the most important tools to use when running any modeling. It breaks down our entire dataset into 2 sections, a training set and a testing set. We use the training set to train our model with an algorithm and then use that algorithm to run on our testing set to make sure that our results is consistent and stable. Another way to think about it is this.\n",
    "\n",
    "We have 100 rows of data. Usually, we want the training set to be much larger than the testing set. I usually use 75-25 split. We will allocate 75% of the data to the training set (completely at random) and 25% of the data to the testing set (whatever is left).\n",
    "\n",
    "It would be a decent 5-7 liner of code if we had to write a training/test function each time, but sklearn's package comes with a train_test_split function!\n",
    "\n",
    "```\n",
    "from sklearn.cross_validation import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, train_size=0.75) # Can also use test_size\n",
    "print trainX.shape, testX.shape\n",
    "print trainY.shape, trainY.shape\n",
    "# trainX and testX should be a data from like (1000,15)\n",
    "# trainY and testY should be a 1D array or list like (1000,)\n",
    "```\n",
    "\n",
    "Another thing to mention that sklearn's train_test_split offers is stratify, which we will use for classification problems. Suppose our target variable is categorical with 0s and 1s, it would be problematic if our train_test_split put all the 0s or all the 1s in the training set with none in the testing set. Stratifying makes sure that there's an equal amount in the training set and the testing set!\n",
    "\n",
    "Below is an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danke_000\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13034, 3) (4345, 3)\n",
      "(13034L,) (4345L,)\n"
     ]
    }
   ],
   "source": [
    "# Continuing from where we left off in patsy!\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, train_size=0.75)\n",
    "print trainX.shape, testX.shape\n",
    "print trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "GridSearchCV is just Grid Search Cross Validation. The goal of GridSearching is to optimize our parameters.\n",
    "\n",
    "Below is a continuation from our train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danke_000\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "# First, we setup our GridSearch parameters for our linear regression\n",
    "search_parameters = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize a blank model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Initialize gridsearch! Verbose shows you what is happening in text.\n",
    "estimator = GridSearchCV(lr, search_parameters, cv=5, verbose=1, n_jobs=4)\n",
    "\n",
    "# Fit the data from our train_test_split\n",
    "results = estimator.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17232674627220104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': False, 'normalize': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "Generally speaking, Gradient Descent is a tool to optimize your coefficients and score. How I imagine it is if you put a ping pong ball in a bowl and let it roll, the ball will end up near the center of the bowl.\n",
    "\n",
    "There are 2 types of Gradient Descent: Batch Gradient Descent and Stochastic Gradient Descent\n",
    "1. Batch Gradient Descent - BGD does the gradient descent on the whole dataset. As you can imagine, this will take a long time! BGD always takes the steepest route to reach the true input distribution. In practice, nobody uses Batch Gradient Descent because it is too computationally expensive for little gain, but it is good to know what it is.\n",
    "2. Stochastic Gradient Descent - SGD computes the gradient by using a single sample. As you can imagine, with a single sample there will be more noise, but doing SGD in minibatches (multiple samples), the gradient can be jerked out of local minimum and into the global minimum. SGD choose a random point and then routes to the steepest gradient. SGD is computationally faster.\n",
    "\n",
    "Below is an example of how to use SGD.\n",
    "```\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_params = {\n",
    "    'loss':['squared_loss'],\n",
    "    'penalty':['l1','l2'],\n",
    "    'alpha':np.linspace(0.01, 10000, 100)\n",
    "}\n",
    "\n",
    "sgd_reg = SGDRegressor()\n",
    "sgd_reg_gs = GridSearchCV(sgd_reg, sgd_params, cv=5, verbose=2)\n",
    "```\n",
    "\n",
    "Gradient Descent uses GridSearchCV to find the most optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A necessary step when performing regularization, must be normalized\n",
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13034L, 3L) (4345L, 3L)\n",
      "(13034L,) (4345L,)\n"
     ]
    }
   ],
   "source": [
    "trainX_n, testX_n, trainY, testY = train_test_split(Xn, y, train_size=0.75)\n",
    "print trainX_n.shape, testX_n.shape\n",
    "print trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   14.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Set SGD params. How to optimize the param will be experience, so it is good to play around with it\n",
    "sgd_params = {\n",
    "    'loss':['squared_loss'],\n",
    "    'penalty':['l1', 'l2'], # L1 is Lasso, L2 is Ridge\n",
    "    'alpha':np.linspace(0.01, 10000, 100)\n",
    "}\n",
    "\n",
    "# Initialize a blank model object\n",
    "sgd_reg = SGDRegressor()\n",
    "\n",
    "# Initialize GridsearchCV params\n",
    "sgd_reg_gs = GridSearchCV(sgd_reg, sgd_params, cv=5, verbose=1)\n",
    "\n",
    "# Fit data\n",
    "sgd_results = sgd_reg_gs.fit(trainX_n, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1796977535872528"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'loss': 'squared_loss', 'penalty': 'l2'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.01, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "I think visually, this might make more sense.\n",
    "```\n",
    "First iteration  = [Train, Train, Train, Train, Test]\n",
    "Second iteration = [Train, Train, Train, Test, Train]\n",
    "Third iteration  = [Train, Train, Test, Train, Train]\n",
    "Fourth iteration = [Train, Test, Train, Train, Train]\n",
    "Fifth iteration  = [Test, Train, Train, Train, Train]\n",
    "```\n",
    "The data will be broken into 5 chunks and every 25% chunk will get a chance to be the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [-1.7911869   0.15853487 -0.36498692  0.12181748  0.15602929  0.12480191\n",
      "  0.11394892  0.14552564  0.02811009 -0.0182731 ]\n",
      "Mean Scores:  -0.132567872404\n"
     ]
    }
   ],
   "source": [
    "# Create a new empty object with the best parameters from GridSearchCV\n",
    "sgd_reg_model = SGDRegressor(alpha=0.01, loss='squared_loss', penalty='l1')\n",
    "\n",
    "# Find the MSE and the mean of all 10 MSE\n",
    "scores = cross_val_score(sgd_reg_model, Xn, y, cv=10)\n",
    "print 'Cross-validated scores:', scores\n",
    "print 'Mean Scores: ', scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Just FYI, my model above sucks</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "Feature Selection is looking at the individual weights for each feature and seeing their relationship with the target variable. The closer to 0, the weaker the effect of the predictor feature is. The higher in positive or negative value (goes either way), the stronger the feature has a relationship with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temp</td>\n",
       "      <td>49.755829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hum</td>\n",
       "      <td>-35.038278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "1       temp   49.755829\n",
       "0  Intercept    0.000000\n",
       "2        hum  -35.038278"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD feature importance results\n",
    "# Create a feature and their importances (coefficients) in a dataframe\n",
    "feature_importance = pd.DataFrame({'feature':X.columns, \n",
    "                                   'importance':sgd_results.best_estimator_.coef_\n",
    "                                  })\n",
    "\n",
    "feature_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temp</td>\n",
       "      <td>248.296988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>151.381310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hum</td>\n",
       "      <td>-194.415780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "1       temp  248.296988\n",
       "0  Intercept  151.381310\n",
       "2        hum -194.415780"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression feature importance results\n",
    "# Create a feature and their importances (coefficients) in a dataframe\n",
    "feature_importance = pd.DataFrame({'feature':X.columns, \n",
    "                                   'importance':results.best_estimator_.coef_\n",
    "                                  })\n",
    "\n",
    "feature_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### cPickle\n",
    "cPickle is one of the greatest packages ever. Think of it as a .zip/.rar/.7z file for pandas! It was one of the tools I used frequently when I was working on my capstone. I had to run 6 Random Forests on 6 different target variables. Let's just say that the algorithm was about 1gb each and took 5 hours each to run once on my laptop. So, how did cPickle save me? I wrote a modeling script, which I uploaded into an AWS EC2 instance. I saved all my data as a .pickle file and uploaded it into the AWS instance. Also in my script, I wrote a save .Pickle file to save my GridSearch information. I didn't have to move any csvs or data cleaning, just a .pickle file. Below is what I did for 1 target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Don't Run the Code Below, it won't work! It is just an example of how I used cPickle.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saved all my cleaned trainX and trainY and 'wb', which is write, into a .pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/edwardlee/Desktop/PROJECTS/NBA Fantasy Project/rank_project/code/pickled_data/trainX_agg.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-da9f3ddf79f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/edwardlee/Desktop/PROJECTS/NBA Fantasy Project/rank_project/code/pickled_data/trainX_agg.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX_agg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/edwardlee/Desktop/PROJECTS/NBA Fantasy Project/rank_project/code/pickled_data/trainY_agg.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainY_agg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/edwardlee/Desktop/PROJECTS/NBA Fantasy Project/rank_project/code/pickled_data/trainX_agg.pickle'"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "with open('/Users/edwardlee/Desktop/PROJECTS/NBA Fantasy Project/rank_project/code/pickled_data/trainX_agg.pickle', 'wb') as f:\n",
    "    pickle.dump(trainX_agg, f)\n",
    "with open('/Users/edwardlee/Desktop/PROJECTS/NBA Fantasy Project/rank_project/code/pickled_data/trainY_agg.pickle', 'wb') as f:\n",
    "    pickle.dump(trainY_agg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The script I ran on my AWS EC2 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('/home/ubuntu/modeling/pickle_input/trainX_agg.pickle', 'rb') as f:\n",
    "    trainX = pickle.load(f)\n",
    "with open('/home/ubuntu/modeling/pickle_input/trainY_agg.pickle', 'rb') as f:\n",
    "    trainY = pickle.load(f)\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "params = {'max_depth':[2,3,4,5,6,None], \n",
    "          'max_features':['auto'],\n",
    "          'min_samples_split':[2,4,8,16,32,64,128,256],\n",
    "          'n_estimators':[500],\n",
    "          'criterion': ['mse']\n",
    "         }\n",
    "\n",
    "estimator_rfr = GridSearchCV(forest, params, n_jobs=-1,  cv=5, verbose=1) \n",
    "\n",
    "model = estimator_rfr.fit(trainX, trainY)\n",
    "\n",
    "with open('/home/ubuntu/modeling/pickle_output/model_agg.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Opened the finished GridSearch algorithm back into my jupyter notebook for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/edwardlee/Desktop/PROJECTS/NBA Fantasy Project/rank_project/code/pickled_data/model_agg.pickle', 'rb') as f:\n",
    "    rf_model_agg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very helpful tool, the AWS instance ran 6 Random Forests in 5 hours, whereas on my laptop, it would have taken 30 hours. Definitely a good tool to save your work at certain points, so you don't have to re-clean everything again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "I've never used pipeline before because I usually forget, but it is a very nifty tool. Pipelines allow you to chain steps together so you don't have to write/run the same code on different datasets. Below is an example of how to use pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize your empty objects\n",
    "ss = StandardScaler()\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the Pipeline to help you run Lasso\n",
    "lr_pipeline = Pipeline(steps=[['scaler', ss], ['linear', lr]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affair = pd.read_csv('review_datasets/affair.csv')\n",
    "affair.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = affair[['age', 'ym', 'religious', 'education', 'occupation', 'rate']]\n",
    "y = affair.nbaffairs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = lr_pipeline.fit(X, y)\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "score = model.score(X, y)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:2.5em;color:blue'>Fix the Code!</span><p>\n",
    "One of the best ways to learn how to code is to break your code, read the error, fix it and break it again. Jupyter notebook is great for breaking your code because worse comes to worse, you can just re-run everything above and try again. Below is a couple of easy fixes that will help you look at what is wrong!\n",
    "\n",
    "The Goal: It needs to be automatic that you can look at the error and identify what is happening. Practice reading errors and documentations.\n",
    "\n",
    "##### If you guys like this format, I can think of a couple more difficult ones with modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = np.read_csv('review_datasets/college-majors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['P25th'].groupby('P25th')['Employed', 'Unemployed']['P25th']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(x='Employed', y='Unemployed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(x='Major', y='Unemployment_rate', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:2.5em;color:blue'>Prework - Tuesday</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models\n",
    "Classification Models are models predicting categorical variables. For example, with given predictor variables, is the next person a male or female? Is the next pet animal a dog or a cat?\n",
    "\n",
    "Here are some classification models:\n",
    "1. kNN (k-Nearest Neighbors)\n",
    "2. Logistic Regression\n",
    "3. Decision Tree Classifier\n",
    "4. Support Vector Classifier\n",
    "5. Naive Bayes Classifier\n",
    "\n",
    "We will start with the most basic classifier, kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN (k-Nearest Neighbors) with sklearn\n",
    "\n",
    "kNN is a lazy model classifier. It runs very fast and efficient, but not very intuitive.\n",
    "\n",
    "```\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights=['uniform', 'distance'])\n",
    "```\n",
    "\n",
    "It only has 2 parameters, which you can play around with.\n",
    "1. n_neighbors - If n_neighbors=5, then based on old data and where the new point lies in the old data, the closest 5 data points will decide what the new data point is. Generally speaking, you want this to be an old number.\n",
    "2. weights - if n_neighbors=5, Uniform says that each one of those points, regradless if they are categorical value 0 or 1, they are all equal. Distance says that the closer the points are to the new data point, kNN puts a heavier weight value (euclidean distance) on those points.\n",
    "\n",
    "It might be easier visualizing it:\n",
    "http://3.bp.blogspot.com/-ZslDMqm5M9o/T8ja_f_fALI/AAAAAAAAAt4/z7w55YAZXpw/s1600/p1.png\n",
    "\n",
    "Below is an example of kNN, I used an affair dataset, which I put in the review and prework folder called review_datasets. I will put datasets I used exclusive from Reid's dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "affairs = pd.read_csv('review_datasets/affair.csv')\n",
    "affairs.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affairs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, we need sex, child and nbaffairs (number of affairs) into categorical values.\n",
    "# I'll show you 2 ways of doing it.\n",
    "\n",
    "# Write a function that whenever number of affairs == 0, that person didn't have affairs and any number greater\n",
    "# than 1 equates to having an affair\n",
    "def binary_affair(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# No need to write any loops because when you data[series].map(function), the .map will take each value 1 by 1,\n",
    "# like a loop.\n",
    "affairs['had_affair'] = affairs['nbaffairs'].map(binary_affair)\n",
    "\n",
    "# Since we don't need to create new columns for sex and child, we can just replace the values into 0 and 1.\n",
    "affairs['sex'] = affairs.sex.map(lambda x: 1 if x == 'male' else 0)\n",
    "affairs['child'] = affairs.child.map(lambda x: 1 if x == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affairs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = affairs[['age', 'religious']]\n",
    "y = affairs['had_affair'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "\n",
    "knn_model = knn.fit(x, y)\n",
    "knn_predict = knn_model.predict(x)\n",
    "knn_score = knn_model.score(x, y)\n",
    "knn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What I did above was a basic run through with zero optimization or any way to test my model. Practice below to see if you can better optimize the score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. kNN Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "For all classification results, the most useful tool to look at is a confusion matrix. Confusion matrix is similar to when we were talking about Type 1 and Type 2 errors. The confusion matrix looks something like this: http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png\n",
    "\n",
    "How do we use a confusion matrix to see how well our model is doing? There are a couple of simplistic formulas we can do to help us figure out how well our model did.\n",
    "\n",
    "*** number of test examples*** _n_ = _tp_  +  _tn_  +  _fp_  +  _fn_ \n",
    "\n",
    "***Accuracy:*** In general how often is the classifier correct? => ( _tp_ + _tn_ )  /  _n_\n",
    "\n",
    "***Misclassification Rate (Error Rate):*** How often is the model wrong =>   _fp_ + _fn_ / _n_\n",
    " \n",
    "***Precision:*** When the model predicts \"yes\", how often is it correct? => _tp_ / ( _tp_  +  _fp_ )\n",
    "\n",
    "***Recall / True Positive Rate:*** How often the model predicts yes, when it's actually yes => _tp_ / ( _tp_ + _fn_ )\n",
    "\n",
    "The good thing is, sklearn provides us with almost all of these information and a confusion matrix :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I will be performing a classification report and a confusion matrix with the simple kNN I did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y, knn_predict, target_names=['no affair', 'had affair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why is there f1-score and support?!\n",
    "\n",
    "```\n",
    "F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "```\n",
    "\n",
    "1. F1-Score is the harmonic mean of the precision and recall. The harmonic mean is used here rather than the more conventional arithmetic mean because the harmonic mean is more appropriate for averaging rates. The f1-score's best value is 1 and worst value is 0, like the precision and recall scores. It is a useful metric for taking into account both measures at once.\n",
    "\n",
    "2. Support is simply the number of observations for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print confusion_matrix(y, knn_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acy = (450. + 7) / 601\n",
    "print acy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Error\n",
    "mis = (143. + 1) / 601\n",
    "print mis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This below code is half borrowed, half edited (mainly to get the tickmarks to not screw up when the target value is not a binomial distribution). Feel free to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    ax = fig.gca()\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size=24)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ax.grid(b=False)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "cnf_mtx = confusion_matrix(y, knn_predict)\n",
    "class_names = affairs['had_affair'].unique()\n",
    "\n",
    "plot_confusion_matrix(cnf_mtx, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write your own classification report and confusion matrix on your optimized model. Is your model doing a good job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:2.5em;color:blue'>Prework - Thursday</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with sklearn\n",
    "Logistic Regression is a classifier used when the target/outcome/dependent variable is categorical (0,1). For most simple cases, the dependent variable will only have 2 outcomes, alive/dead, male/female, pass/fail, win/lose, etc... However, logistic regression can also be used if the dependent variable has multiple outcomes, such as big/medium/small, up/down/left/right, etc... we call these multinomial logistic regression.\n",
    "\n",
    "The goal of a logistic regression is to use independent variable(s) and predicting the probability if the dependent variable will be 0 or 1. For example, the Sigmoid (S-shaped graph) shows the probability of passing or failiing a test depending on how much studying you do: https://upload.wikimedia.org/wikipedia/commons/6/6d/Exam_pass_logistic_curve.jpeg\n",
    "\n",
    "A Logistic Regression's syntax:\n",
    "```\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "```\n",
    "\n",
    "Since it is better to practice, try running a logistic regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "affair = pd.read_csv('review_datasets/affair.csv')\n",
    "affair.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affair.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affair.nbaffairs.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This will be a categorical target variable\n",
    "affair['had_affairs'] = affair.nbaffairs.map(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-family:Georgia; font-size:1.5em;\">Don't copy and paste. Look up documentations and try to create the code. Don't read stackoverflow, it ends up being copying and pasting. Breaking codes and creating errors is the best way to learn how to code. The more errors you make, the better you'll be.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As done above, change sex and child to 0 and 1 categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Patsy\n",
    "Make your target variable had_affairs, you choose your predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split\n",
    "Create a training set and a testing set. Play around with different percentages to see how your model changes. Also, remember to stratify=y in the parameter so that there is an even split of 0 and 1s in the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a Logistic Regression\n",
    "So, here's a general explanation on how the training and testing set work.\n",
    "\n",
    "If you want to see how well your training set did:\n",
    "```\n",
    "logreg  = LogisticRegression()\n",
    "model   = logreg.fit(trainX, trainY)\n",
    "predict = model.predict(trainX)\n",
    "score   = model.score(trainX, trainY)\n",
    "```\n",
    "If you want to see if the training set was not over or underfitting:\n",
    "```\n",
    "logreg  = LogisticRegression()\n",
    "model   = logreg.fit(trainX, trainY)\n",
    "predict = model.predict(testX)\n",
    "score   = model.score(testX, testY)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Confusion Matrix and Classification Report\n",
    "\n",
    "Is your model predicting well? If not, how would you improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Graph and Odds Ratio\n",
    "\n",
    "Sigmoid Graphs are log function graphs (creates an S shape like this: https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png). Although it looks like it is on 0 and 1, it is actually never reaching 0.0 or 1.0. It'll go on to infinity.\n",
    "\n",
    "Below is the equation for Odds Ratio:\n",
    "### $$\\text{odds ratio}(p) = \\frac{p}{1-p}$$\n",
    "So, what does that mean? Well, Odds Ratio and probability represent the same thing, but in a different way. The easiest way to think about Odds Ratio is betting returns!\n",
    "\n",
    "If something has a 50% chance of happening, then the Odds Ratio is 1. Which means, if you put in 1 dollar, you'll get 1 dollar back!\n",
    "\n",
    "Below is an example of visualizing Sigmoid Graph and why Odds Ratio is useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a simple dataset of a student being admitted to a master's degree program or not\n",
    "admissions = pd.read_csv('review_datasets/admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admissions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admissions.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basically, since we only want to see the most prestigious people, we need to create and emulate more rows\n",
    "admit = admissions[admissions.prestige == 1]\n",
    "\n",
    "admit = pd.concat([admit]*10, axis=0)\n",
    "\n",
    "admit.loc[admit.admit == 1, 'gpa'] += np.random.random(size=admit[admit.admit == 1].shape[0])\n",
    "admit.loc[admit.admit == 0, 'gpa'] -= np.random.random(size=admit[admit.admit == 0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = admit.admit.values\n",
    "X = admit[['gpa']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print 'Intercept: ', logreg.intercept_\n",
    "print 'Coefficients: ', logreg.coef_\n",
    "print 'Logreg predicted probabilities: ', logreg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the baseline, when the probability of being admitted and rejected are both 50%\n",
    "# The reason why you need a baseline is because if your model predicts close to a 50-50 chance, then your model\n",
    "# is no better than if you flipped a fair coin\n",
    "\n",
    "xval_chance = (-1 * logreg.intercept_[0])/logreg.coef_[0][0]\n",
    "print 'predicted_y_value = 0: ', xval_chance*logreg.coef_[0][0] + logreg.intercept_\n",
    "print 'GPA when admit/reject is 50/50: ', xval_chance\n",
    "\n",
    "print 'Check probability: ', logreg.predict_proba(xval_chance)\n",
    "\n",
    "# Having the baseline is important because we can plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "# plot the logreg regression line for admit ~ gpa\n",
    "x_vals = np.linspace(-1.,5.,300)\n",
    "y_pp = logreg.predict_proba(x_vals[:, np.newaxis])[:,1]\n",
    "\n",
    "ax.plot(x_vals, y_pp, color='black', alpha=0.7, lw=4)\n",
    "\n",
    "# A scatter plot for each type of category\n",
    "ax.scatter(admit.gpa[admit.admit == 0],\n",
    "           admit.admit[admit.admit == 0],\n",
    "           c='orange', s=100, alpha=0.7,\n",
    "           label='rejected')\n",
    "\n",
    "ax.scatter(admit.gpa[admit.admit == 1],\n",
    "           admit.admit[admit.admit == 1],\n",
    "           c='blue', s=100, alpha=0.7,\n",
    "           label='admitted')\n",
    "\n",
    "# Plotting the baseline value!\n",
    "ax.axvline(xval_chance, lw=3, color='red', ls='dashed',\n",
    "           label='gpa where P(y = 1) = 0.5')\n",
    "\n",
    "ax.set_ylabel('admitted', fontsize=16)\n",
    "ax.set_xlabel('gpa', fontsize=16)\n",
    "ax.set_title('admittance ~ gpa, prestige=1\\n', fontsize=20)\n",
    "\n",
    "ax.set_xlim([2.,5.])\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting your coefficients can be counter-intuitive, so we will use log odds. How?\n",
    "1. We will need to center the predictor values. Centering helps a lot because now the \"baseline\" for the predictor, the value at 0, is the mean of the predictor. So, in our case, when gpa = 0 this is the average gpa across students.\n",
    "2. Re-run our Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_center = X - X.mean()\n",
    "print X_center[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "model2  = logreg2.fit(X_center, y)\n",
    "\n",
    "print 'Intercept: ', model2.intercept_[0]\n",
    "print 'Coefficients: ', model2.coef_[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of converting the probability to an odds ratio and taking the logarithm of that is called the **logit link function**, and is what Logistic Regression uses to estimate probability:\n",
    "\n",
    "##### If you are wondering about the equation, you can find it through wikipedia and other sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_transformation(gpa, b0, b1):\n",
    "    regression_sum = b0 + b1*gpa\n",
    "    exponentiated = np.exp(regression_sum)\n",
    "    return exponentiated / (1 + exponentiated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'average gpa:', np.mean(X[:,0])\n",
    "print 'P(admitted | average gpa = 3.49):', logistic_transformation(0, model2.intercept_[0], model2.coef_[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'gpa = 2.5, difference from mean:', 2.5 - np.mean(X[:,0])\n",
    "print 'P(admitted | gpa = 2.5):', logistic_transformation(2.5 - np.mean(X[:,0]), \n",
    "                                                          model2.intercept_[0], model2.coef_[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'gpa = 4, difference from mean:', 4 - np.mean(X[:,0])\n",
    "print 'P(admitted | gpa = 4):', logistic_transformation(4. - np.mean(X[:,0]), \n",
    "                                                        model2.intercept_[0], model2.coef_[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC / AUC\n",
    "\n",
    "Response Operating Curve/Receiver Operating Characteristic and Area Under the Curve are the official names. I will explain it in more detail on what it does later.\n",
    "\n",
    "Below is a function I wrote a while back that does train_test_split, Logistic Regression and plotting a ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def logistic_regression_calculation(predictors, target, title='Your Prediction'):\n",
    "    \n",
    "    ### Test-Train split 70-30\n",
    "    trainX, testX, trainY, testY = train_test_split(predictors, target, train_size=0.7, stratify=target)\n",
    "    print 'trainX shape: ', trainX.shape, '\\ntestX shape:', testX.shape\n",
    "    print 'trainY shape: ', trainY.shape, '\\ntestY shape:', testY.shape\n",
    "    \n",
    "    ### Setup LogisticRegression modeling\n",
    "    # Create LogisticRegression function cross validated 5 times\n",
    "    logreg = LogisticRegression()\n",
    "    # Fit the data points into the LogisticRegression model\n",
    "    model = logreg.fit(trainX, trainY)\n",
    "    # Predict Probability\n",
    "    probabilities = model.predict_proba(testX)\n",
    "    # Score the model\n",
    "    score = model.score(testX, testY)\n",
    "    print 'Model Score: ', score\n",
    "    \n",
    "    ### Plot the data\n",
    "    # Creating a blank set of objects to store my confusion matrix metrics here\n",
    "    FPR = dict()\n",
    "    TPR = dict()\n",
    "    ROC_AUC = dict()\n",
    "\n",
    "    # I am assigning the 1st offsets to my FPR / TPR from the 2nd set of probabiliies from my\n",
    "    # .predict_proba() predictions\n",
    "    # This data is what will be plotted once we throw it to our figure\n",
    "    FPR[1], TPR[1], _ = roc_curve(testY, probabilities[:, 1])\n",
    "    ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "    # 1. Initialize a blank plot, aspect 11x9\n",
    "    plt.figure(figsize=[11,9])\n",
    "    # 2. Plot my false and true rates (returned from roc_curve function)\n",
    "    plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "    # 3. Plotting a dotted line diagonally, representing the .5\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.title('Receiver operating characteristic for %s' %title, fontsize=18)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "logistic_regression_calculation(X, y, title='for Admitted vs Rejected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC/AUC curve plots the True Positives vs False Positive. The dotted line is the baseline, which is 50% (area = 0). In order for your model to be predicting well, you need a high area between the curve and the baseline. A good model will have a positive area, while a really bad model will have a negative area.\n",
    "\n",
    "We want to limit the false positives because we don't want our model to cause Type II errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Classification Report and Confusion Matrix and see how it relates with the ROC/AUC curve above. Is this a good model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-family:Georgia; font-size:1.5em;\">Again, try to remember what the imports are and read the documentation for the parameters.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
